{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 셋 파악\n",
    "#### 전체 데이터 샘플 수\n",
    "- Training set : 60000 samples\n",
    "- Test set : 10000 samples\n",
    "\n",
    "#### 전처리하기 전 MNIST 로우 데이터 모양 확인\n",
    "- raw_dataset[i] ->  raw_dataset의 샘플을 튜플 형태로 반환\n",
    "- (28X28 사이즈 흑백 이미지, Label) 로 이루어진 튜플임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 기본 파이토치 기능\n",
    "import torch.nn as nn # nn 모듈 기능\n",
    "import torch.nn.functional as F # 기본 신경망 함수\n",
    "import torch.optim as optim # 최적화\n",
    "from torchvision import datasets, transforms # 데이터셋 처리\n",
    "import matplotlib.pyplot as plt # 데이터 시각화\n",
    "\n",
    "# ========================\n",
    "# 1. 데이터 로드 및 전처리\n",
    "# ========================\n",
    "def load_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # 평균 0.5, 표준편차 0.5로 정규화\n",
    "    ])\n",
    "    # 학습 데이터 셋 다운로드 60000개 / 저장 위치는 root의 data 폴더 \n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    # 테스트 데이터 셋 다운로드 10000개 / 저장 위치는 root의 data 폴더 \n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    # 6만개 샘플들을 64 배치 사이즈 설정 및 셔플 설정하여 랜덤하게 train_loader에 담는다. \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # 1만개 샘플들을 64 배치 사이즈 설정 및 셔플 미설정하여 순서대로 test_loader에 담는다. \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 전처리를 위한 코드\n",
    "- 배치 사이즈는 64개 (28x28 사이즈 텐서 64개가 차례대로 입력되어 64개가 쌓이면 64개의 텐서를 한번에 모델에서 처리하여 64개 분류 작업 실행)\n",
    "- 해당 함수를 메인에서 불러서 64개 배치 사이즈로 설정한 60000개 샘플과 10000개 샘플을 train_loader와 test_loader에 담아 반환해준다. \n",
    "\n",
    "#### _loader 객체 \n",
    "- torch.utils.data.DataLoader는 Batch단위로 데이터가 적재됨. 그래서 Batch size 설정이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. 모델 정의\n",
    "# ========================\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # super(CNN,self)는 부모 클래스 nn.module의 INIT 메서드를 호출하여 제대로 상속받도록 한다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1채널 28x28 (1x28x28) -> 32채널 28x28 (32x28x28)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32채널 28x28 (32x28x28) -> 64채널 28x28 (32x28x28)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x28x28 -> 64x14x14\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        # self.fc1 = None  # Input size will be dynamically calculated\n",
    "        self.fc1 = nn.Linear(12544, 128) # 동적으로 초기화하던 fc1을 정적 초기화하도록 수정\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer: 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Apply Conv2D and MaxPooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten tensor to 2D\n",
    "\n",
    "        # Dynamically initialize fc1 based on input size\n",
    "        #if self.fc1 is None:\n",
    "        #    self.fc1 = nn.Linear(x.size(1), 128).to(x.device)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __init__ ()\n",
    "#### super(CNN, self).__init__()을 해야하는 이유\n",
    "- super(LeNet5, self).__init__()는 부모 클래스인 nn.Module의 초기화 메서드를 호출하여 LeNet5 클래스가 PyTorch의 모델 클래스 기능을 제대로 상속받고 사용할 수 있도록 보장\n",
    "- 특히 nn.Module은 학습 가능한 파라미터 관리, 계층 추적 등의 핵심 기능을 제공하므로, 이를 호출하지 않으면 모델이 제대로 작동하지 않음\n",
    "#### 모델의 구조(레이어)를 정의하거나 속성을 초기화하는 데 사용. 객체가 생성될 때 실행.\n",
    "- conv1 layer : 1채널에서 32채널로, 커널 사이즈 3x3, 패딩 = 1 (이미지 사이즈 유지됨) 32x28x28 \n",
    "- conv2 layer : 32채널에서 64채널로, 커널 사이즈 3x3, 패딩 = 1 (이미지 사이즈 유지됨) 64x28x28\n",
    "- pooling layer : 2x2 크기 Max pooling !! \n",
    "- fully connected layer 1 : 가변적 크기 \n",
    "- fully connected layer 2 : 레이어 입력 크기 1x128 크기, 레이어 출력 크기 1x10 (최종 10class 분류)\n",
    "\n",
    "### forward ()\n",
    "#### 데이터가 모델을 통과하는 동안 실행되는 메서드. 레이어 간의 연결 방식을 정의.\n",
    "- __init__ () 단계에서 정적 초기화되는 레이어들 conv1, conv2, pool, fc2\n",
    "- fc1은 forward () 단계에서 초기화하므로 동적 초기화임\n",
    "- x.view에서 x.size(0) 는 x의 0번째 차원 사이즈. 즉, 배치 사이즈를 의미 (64x64x28x28에서 pooling했으므로 64x64x14x14 차원이 됨)\n",
    "- 64x64x28x28 -> 배치 사이즈 x 채널 사이즈 x 픽셀 사이즈 x 픽셀 사이즈\n",
    "\n",
    "\n",
    "### 코드 진행 순서\n",
    "#### 정적 초기화\n",
    "1) __init__ 메서드에서 정적으로 레이어를 초기화.\n",
    "2) 초기화된 레이어의 파라미터는 기본적으로 CPU에 생성.\n",
    "3) model.to(device) 호출 시, 모델 전체가 지정된 장치(CPU 또는 GPU)로 이동. -> **이 시점에는 fc1레이어는 존재하지 않았음**\n",
    "#### 동적 초기화\n",
    "1) forward 실행 중 필요 시 레이어를 동적으로 초기화. -> **이때 fc1이 동적 초기화를 통해 생성되었음**\n",
    "2) 이때, to(x.device)에 의해 데이터가 위치한 장치로 바로 이동.\n",
    "\n",
    "\n",
    "### fc1의 동적 초기화\n",
    "- fc1이 굳이 동적 초기화해야하는 이유는? MNIST 데이터셋은 고정된 사이즈의 이미지만 처리하고 있음. fc1의 인풋 사이즈는 달라지지 않음. 그럼 정적 초기화 해도 되지 않는지?\n",
    "- 정적 초기화하도록 수정하면 학습 및 결과가 달라지는지 확인 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. 학습 함수\n",
    "# ========================\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device) \n",
    "    # 모델의 (정적 초기화 레이어의 파라미터 및 버퍼) cpu 디바이스로 보내짐 (근데 원래 cpu에서 생성되었음)\n",
    "    # 모델이 원래 cpu에서 생성되었으므로, 사실 위치를 변경하지 않으나, 코드의 일관성, 호환성, 안정성, 명확성을 위하여 코드로 명시하는 것이 좋음\n",
    "    # 추후 GPU에서 학습 시 모델을 GPU로 보내기 위해 값을 변경해주어야 함 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # 모델을 training mode로 전환\n",
    "        total_loss = 0 # loss 값 초기화 \n",
    "        for images, labels in train_loader: # 훈련 셋의 배치 단위로 images, lables 반환이 반복됨 \n",
    "            images, labels = images.to(device), labels.to(device) # 데이터x도 cpu 디바이스로 보냄. (마찬가지로 GPU로 변경 시 GPU로 보내짐)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) # images만 모델에 입력\n",
    "            loss = criterion(outputs, labels) # 모델 출력 결과와 정답 비교하여 loss 계산 \n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad() # 옵티마이저의 기울기 초기화 \n",
    "            loss.backward() # 손실에 대한 기울기 계산 \n",
    "            optimizer.step() # 옵티마이저의 최적화 단계 수행\n",
    "\n",
    "            total_loss += loss.item() # 손실 누적 값 계산 \n",
    "        \n",
    "        # 한 Epoch에서의 평균 손실 출력\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 학습시키는 함수\n",
    "#### Args (arguments)\n",
    "- model (nn.Module): 학습할 모델\n",
    "- train_loader (DataLoader): 학습 데이터 로더\n",
    "- criterion (Loss): 손실 함수\n",
    "- optimizer (Optimizer): 최적화 알고리즘\n",
    "- num_epochs (int): 학습할 에포크 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. 평가 함수\n",
    "# ========================\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images) # output = 64 x 10 (배치 사이즈 x 10차원 행벡터)\n",
    "            _, predicted = torch.max(outputs, 1) # torch.max의 반환 값은 튜플 : 각 행의 최대값, 각 행의 최대값 인덱스\n",
    "            total += labels.size(0) # 현재 샘플 갯수 (배치 단위로 더함 64+64+ ... )\n",
    "            correct += (predicted == labels).sum().item() # (predicted == labels)는 Boolean 값이고, 이것 또한 batch size 단위로 계산됨. 즉 64 차원의 Boolean값이 저장된 텐서임\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 단계\n",
    "- with 구문 : 컨텍스트 매니저를 사용하는 구문\n",
    "- torch.no_grad()는 PyTorch의 컨텍스트 매니저로, 블록 내에서 **자동 미분(gradient 계산)**을 비활성화함\n",
    "- _, predicted = torch.max(outputs, 1) : output은 64x10의 텐서. (배치 사이즈 x 행벡터 차원)\n",
    "**예시**\n",
    "output은 10개의 행벡터(각 데이터 마다의 예측값)이 64배치사이즈로 결합되어 있음\n",
    "[[x, x, x, x, x, max, x, x, x, x], : 예측값1\n",
    " [x, x, x, x, x, x, x, max, x, x], : 예측값2\n",
    " ...\n",
    " [x, x, x, x, x, x, x, x, x, max], : 예측값63\n",
    " [x, x, max, x, x, x, x, x, x, x]] : 예측값64\n",
    "\n",
    "- labels는 torchvision으로부터 dataset을 불러올 때 **배열** 형태로 불러와지고, torch.utils.data.DataLoader에 의하여 64 배치 사이즈 단위가 생김\n",
    "- 배열의 차원은 1개 즉 labels.size(0) = 64\n",
    "\n",
    "#### total 변수 누적 과정\n",
    "| **Iteration**    | **labels.size(0)**      | **Total**      |\n",
    "|-------------------|-------------------------|----------------|\n",
    "| 1                | 64                      | 64             |\n",
    "| 2                | 64                      | 128            |\n",
    "| 3                | 64                      | 192            |\n",
    "| ...              | ...                     | ...            |\n",
    "| 마지막 배치       | 32 (잔여 샘플)          | 60000          |\n",
    "\n",
    "#### .sum().item()\n",
    "텐서의 합을 구하고 accuracy 계산을 위해 스칼라 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5. 예측 시각화\n",
    "# ========================\n",
    "def visualize_predictions(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(test_loader) # test_loader를 iterator로 변환 (데이터를 직접 순회하기 위해)\n",
    "    images, labels = next(data_iter) # 이터레이터를 생성하고 바로 next()를 호출하면 맨 처음 값부터 가져 옴\n",
    "    images, labels = images[:5].to(device), labels[:5].to(device) # 처음부터 5까지 이미지랑 레이블을 디바이스로 보냄\n",
    "\n",
    "    # 모델 예측\n",
    "    outputs = model(images) # 모델에 이미지를 입력하고 아웃풋을 저장\n",
    "    _, preds = torch.max(outputs, 1) # 예측값을 preds 변수에 저장 \n",
    "\n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3)) # \n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[idx].item()}\\nPred: {preds[idx].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화\n",
    "#### plt.subplots ()\n",
    "- Matplotlib를 사용하여 1행 5열의 서브플롯(각각의 작은 그래프)을 생성하고, 그래프의 전체 크기를 지정\n",
    "* fig: 전체 그래프(figure)를 나타냄.\n",
    "* axes: 서브플롯(개별 그래프)을 나타내는 객체(또는 배열).\n",
    "* figsize: 전체 그래프의 크기(가로, 세로 크기).\n",
    "\n",
    "\n",
    "#### images[idx].cpu().squeeze()\n",
    "images[idx]: 배치에서 idx 번째 샘플 선택. 크기: [1, 28, 28].\n",
    ".cpu(): 텐서를 GPU에서 CPU로 이동.\n",
    ".squeeze(): 크기 1인 차원(채널 차원)을 제거. 최종 크기: [28, 28].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1414\n",
      "Epoch [2/5], Loss: 0.0386\n",
      "Epoch [3/5], Loss: 0.0222\n",
      "Epoch [4/5], Loss: 0.0152\n",
      "Epoch [5/5], Loss: 0.0107\n",
      "Accuracy on test set: 98.87%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# 6. 메인 실행\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 하이퍼파라미터\n",
    "    batch_size = 64\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 모델 학습\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # 모델 평가\n",
    "    evaluate_model(model, test_loader)\n",
    "\n",
    "    # 예측 시각화\n",
    "    visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
