{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 셋 파악\n",
    "#### 전체 데이터 샘플 수\n",
    "- Training set : 60000 samples\n",
    "- Test set : 10000 samples\n",
    "\n",
    "#### 전처리하기 전 MNIST 로우 데이터 모양 확인\n",
    "- raw_dataset[i] ->  raw_dataset의 샘플을 튜플 형태로 반환\n",
    "- (28X28 사이즈 흑백 이미지, Label) 로 이루어진 튜플임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 기본 파이토치 기능\n",
    "import torch.nn as nn # nn 모듈 기능\n",
    "import torch.nn.functional as F # 기본 신경망 함수\n",
    "import torch.optim as optim # 최적화\n",
    "from torchvision import datasets, transforms # 데이터셋 처리\n",
    "import matplotlib.pyplot as plt # 데이터 시각화\n",
    "\n",
    "# ========================\n",
    "# 1. 데이터 로드 및 전처리\n",
    "# ========================\n",
    "def load_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # 평균 0.5, 표준편차 0.5로 정규화\n",
    "    ])\n",
    "    # 학습 데이터 셋 다운로드 60000개 / 저장 위치는 root의 data 폴더 \n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    # 테스트 데이터 셋 다운로드 10000개 / 저장 위치는 root의 data 폴더 \n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    # 6만개 샘플들을 64 배치 사이즈 설정 및 셔플 설정하여 랜덤하게 train_loader에 담는다. \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # 1만개 샘플들을 64 배치 사이즈 설정 및 셔플 미설정하여 순서대로 test_loader에 담는다. \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 전처리를 위한 코드\n",
    "- 배치 사이즈는 64개 (28x28 사이즈 텐서 64개가 차례대로 입력되어 64개가 쌓이면 64개의 텐서를 한번에 모델에서 처리하여 64개 분류 작업 실행)\n",
    "- 해당 함수를 메인에서 불러서 64개 배치 사이즈로 설정한 60000개 샘플과 10000개 샘플을 train_loader와 test_loader에 담아 반환해준다. \n",
    "\n",
    "#### _loader 객체 \n",
    "- torch.utils.data.DataLoader는 Batch단위로 데이터가 적재됨. 그래서 Batch size 설정이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. 모델 정의\n",
    "# ========================\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # super(CNN,self)는 부모 클래스 nn.module의 INIT 메서드를 호출하여 제대로 상속받도록 한다.\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1채널 28x28 (1x28x28) -> 32채널 28x28 (32x28x28)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32채널 28x28 (32x28x28) -> 64채널 28x28 (32x28x28)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x28x28 -> 64x14x14\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        # self.fc1 = None  # Input size will be dynamically calculated\n",
    "        self.fc1 = nn.Linear(12544, 128) # 동적으로 초기화하던 fc1을 정적 초기화하도록 수정\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer: 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Apply Conv2D and MaxPooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten tensor to 2D\n",
    "\n",
    "        # Dynamically initialize fc1 based on input size\n",
    "        #if self.fc1 is None:\n",
    "        #    self.fc1 = nn.Linear(x.size(1), 128).to(x.device)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __init__ ()\n",
    "#### super(CNN, self).__init__()을 해야하는 이유\n",
    "- super(LeNet5, self).__init__()는 부모 클래스인 nn.Module의 초기화 메서드를 호출하여 LeNet5 클래스가 PyTorch의 모델 클래스 기능을 제대로 상속받고 사용할 수 있도록 보장\n",
    "- 특히 nn.Module은 학습 가능한 파라미터 관리, 계층 추적 등의 핵심 기능을 제공하므로, 이를 호출하지 않으면 모델이 제대로 작동하지 않음\n",
    "#### 모델의 구조(레이어)를 정의하거나 속성을 초기화하는 데 사용. 객체가 생성될 때 실행.\n",
    "- conv1 layer : 1채널에서 32채널로, 커널 사이즈 3x3, 패딩 = 1 (이미지 사이즈 유지됨) 32x28x28 \n",
    "- conv2 layer : 32채널에서 64채널로, 커널 사이즈 3x3, 패딩 = 1 (이미지 사이즈 유지됨) 64x28x28\n",
    "- pooling layer : 2x2 크기 Max pooling !! \n",
    "- fully connected layer 1 : 가변적 크기 \n",
    "- fully connected layer 2 : 레이어 입력 크기 1x128 크기, 레이어 출력 크기 1x10 (최종 10class 분류)\n",
    "\n",
    "### forward ()\n",
    "#### 데이터가 모델을 통과하는 동안 실행되는 메서드. 레이어 간의 연결 방식을 정의.\n",
    "- __init__ () 단계에서 정적 초기화되는 레이어들 conv1, conv2, pool, fc2\n",
    "- fc1은 forward () 단계에서 초기화하므로 동적 초기화임\n",
    "- x.view에서 x.size(0) 는 x의 0번째 차원 사이즈. 즉, 배치 사이즈를 의미 (64x64x28x28에서 pooling했으므로 64x64x14x14 차원이 됨)\n",
    "- 64x64x28x28 -> 배치 사이즈 x 채널 사이즈 x 픽셀 사이즈 x 픽셀 사이즈\n",
    "\n",
    "\n",
    "### 코드 진행 순서\n",
    "#### 정적 초기화\n",
    "1) __init__ 메서드에서 정적으로 레이어를 초기화.\n",
    "2) 초기화된 레이어의 파라미터는 기본적으로 CPU에 생성.\n",
    "3) model.to(device) 호출 시, 모델 전체가 지정된 장치(CPU 또는 GPU)로 이동. -> **이 시점에는 fc1레이어는 존재하지 않았음**\n",
    "#### 동적 초기화\n",
    "1) forward 실행 중 필요 시 레이어를 동적으로 초기화. -> **이때 fc1이 동적 초기화를 통해 생성되었음**\n",
    "2) 이때, to(x.device)에 의해 데이터가 위치한 장치로 바로 이동.\n",
    "\n",
    "\n",
    "### fc1의 동적 초기화\n",
    "- fc1이 굳이 동적 초기화해야하는 이유는? MNIST 데이터셋은 고정된 사이즈의 이미지만 처리하고 있음. fc1의 인풋 사이즈는 달라지지 않음. 그럼 정적 초기화 해도 되지 않는지?\n",
    "- 정적 초기화하도록 수정하면 학습 및 결과가 달라지는지 확인 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. 학습 함수\n",
    "# ========================\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device) \n",
    "    # 모델의 (정적 초기화 레이어의 파라미터 및 버퍼) cpu 디바이스로 보내짐 (근데 원래 cpu에서 생성되었음)\n",
    "    # 모델이 원래 cpu에서 생성되었으므로, 사실 위치를 변경하지 않으나, 코드의 일관성, 호환성, 안정성, 명확성을 위하여 코드로 명시하는 것이 좋음\n",
    "    # 추후 GPU에서 학습 시 모델을 GPU로 보내기 위해 값을 변경해주어야 함 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # 모델을 training mode로 전환\n",
    "        total_loss = 0 # loss 값 초기화 \n",
    "        for images, labels in train_loader: # 훈련 셋의 배치 단위로 images, lables 반환이 반복됨 \n",
    "            images, labels = images.to(device), labels.to(device) # 데이터x도 cpu 디바이스로 보냄. (마찬가지로 GPU로 변경 시 GPU로 보내짐)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) # images만 모델에 입력\n",
    "            loss = criterion(outputs, labels) # 모델 출력 결과와 정답 비교하여 loss 계산 \n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad() # 옵티마이저의 기울기 초기화 \n",
    "            loss.backward() # 손실에 대한 기울기 계산 \n",
    "            optimizer.step() # 옵티마이저의 최적화 단계 수행\n",
    "\n",
    "            total_loss += loss.item() # 손실 누적 값 계산 \n",
    "        \n",
    "        # 한 Epoch에서의 평균 손실 출력\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 학습시키는 함수\n",
    "#### Args (arguments)\n",
    "- model (nn.Module): 학습할 모델\n",
    "- train_loader (DataLoader): 학습 데이터 로더\n",
    "- criterion (Loss): 손실 함수\n",
    "- optimizer (Optimizer): 최적화 알고리즘\n",
    "- num_epochs (int): 학습할 에포크 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. 평가 함수\n",
    "# ========================\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images) # output = 64 x 10 (배치 사이즈 x 10차원 행벡터)\n",
    "            _, predicted = torch.max(outputs, 1) # torch.max의 반환 값은 튜플 : 각 행의 최대값, 각 행의 최대값 인덱스\n",
    "            total += labels.size(0) # 현재 샘플 갯수 (배치 단위로 더함 64+64+ ... )\n",
    "            correct += (predicted == labels).sum().item() # (predicted == labels)는 Boolean 값이고, 이것 또한 batch size 단위로 계산됨. 즉 64 차원의 Boolean값이 저장된 텐서임\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 단계\n",
    "- with 구문 : 컨텍스트 매니저를 사용하는 구문\n",
    "- torch.no_grad()는 PyTorch의 컨텍스트 매니저로, 블록 내에서 **자동 미분(gradient 계산)**을 비활성화함\n",
    "- _, predicted = torch.max(outputs, 1) : output은 64x10의 텐서. (배치 사이즈 x 행벡터 차원)\n",
    "**예시**\n",
    "output은 10개의 행벡터(각 데이터 마다의 예측값)이 64배치사이즈로 결합되어 있음\n",
    "[[x, x, x, x, x, max, x, x, x, x], : 예측값1\n",
    " [x, x, x, x, x, x, x, max, x, x], : 예측값2\n",
    " ...\n",
    " [x, x, x, x, x, x, x, x, x, max], : 예측값63\n",
    " [x, x, max, x, x, x, x, x, x, x]] : 예측값64\n",
    "\n",
    "- labels는 torchvision으로부터 dataset을 불러올 때 **배열** 형태로 불러와지고, torch.utils.data.DataLoader에 의하여 64 배치 사이즈 단위가 생김\n",
    "- 배열의 차원은 1개 즉 labels.size(0) = 64\n",
    "\n",
    "#### total 변수 누적 과정\n",
    "| **Iteration**    | **labels.size(0)**      | **Total**      |\n",
    "|-------------------|-------------------------|----------------|\n",
    "| 1                | 64                      | 64             |\n",
    "| 2                | 64                      | 128            |\n",
    "| 3                | 64                      | 192            |\n",
    "| ...              | ...                     | ...            |\n",
    "| 마지막 배치       | 32 (잔여 샘플)          | 60000          |\n",
    "\n",
    "#### .sum().item()\n",
    "텐서의 합을 구하고 accuracy 계산을 위해 스칼라 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5. 예측 시각화\n",
    "# ========================\n",
    "def visualize_predictions(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(test_loader) # test_loader를 iterator로 변환 (데이터를 직접 순회하기 위해)\n",
    "    images, labels = next(data_iter) # 이터레이터를 생성하고 바로 next()를 호출하면 맨 처음 값부터 가져 옴\n",
    "    images, labels = images[:5].to(device), labels[:5].to(device) # 처음부터 5까지 이미지랑 레이블을 디바이스로 보냄\n",
    "\n",
    "    # 모델 예측\n",
    "    outputs = model(images) # 모델에 이미지를 입력하고 아웃풋을 저장\n",
    "    _, preds = torch.max(outputs, 1) # 예측값을 preds 변수에 저장 \n",
    "\n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3)) # \n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[idx].item()}\\nPred: {preds[idx].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화\n",
    "#### plt.subplots ()\n",
    "- Matplotlib를 사용하여 1행 5열의 서브플롯(각각의 작은 그래프)을 생성하고, 그래프의 전체 크기를 지정\n",
    "* fig: 전체 그래프(figure)를 나타냄.\n",
    "* axes: 서브플롯(개별 그래프)을 나타내는 객체(또는 배열).\n",
    "* figsize: 전체 그래프의 크기(가로, 세로 크기).\n",
    "\n",
    "\n",
    "#### images[idx].cpu().squeeze()\n",
    "images[idx]: 배치에서 idx 번째 샘플 선택. 크기: [1, 28, 28].\n",
    ".cpu(): 텐서를 GPU에서 CPU로 이동.\n",
    ".squeeze(): 크기 1인 차원(채널 차원)을 제거. 최종 크기: [28, 28].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1395\n",
      "Epoch [2/5], Loss: 0.0427\n",
      "Epoch [3/5], Loss: 0.0241\n",
      "Epoch [4/5], Loss: 0.0178\n",
      "Epoch [5/5], Loss: 0.0115\n",
      "Accuracy on test set: 98.76%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# 6. 메인 실행\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 하이퍼파라미터\n",
    "    batch_size = 64\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 모델 학습\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # 모델 평가\n",
    "    evaluate_model(model, test_loader)\n",
    "\n",
    "    # 예측 시각화\n",
    "    visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
