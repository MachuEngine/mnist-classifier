{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch # 기본 파이토치 기능\n",
    "import torch.nn as nn # nn 모듈 기능\n",
    "import torch.nn.functional as F # 기본 신경망 함수\n",
    "import torch.optim as optim # 최적화\n",
    "from torchvision import datasets, transforms # 데이터셋 처리\n",
    "import matplotlib.pyplot as plt # 데이터 시각화\n",
    "\n",
    "# ========================\n",
    "# 1. 데이터 로드 및 전처리\n",
    "# ========================\n",
    "def load_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # 평균 0.5, 표준편차 0.5로 정규화\n",
    "    ])\n",
    "    # 학습 데이터 셋 다운로드 60000개 / 저장 위치는 root의 data 폴더 \n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    # 테스트 데이터 셋 다운로드 10000개 / 저장 위치는 root의 data 폴더 \n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    # 6만개 샘플들을 64 배치 사이즈 설정 및 셔플 설정하여 랜덤하게 train_loader에 담는다. \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # 1만개 샘플들을 64 배치 사이즈 설정 및 셔플 미설정하여 순서대로 test_loader에 담는다. \n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # C1: 합성곱 층 (입력: 1x32x32 → 출력: 6x28x28)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        # S2: 평균 풀링 층 (출력: 6x14x14)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # C3: 합성곱 층 (출력: 16x10x10)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        # S4: 평균 풀링 층 (출력: 16x5x5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # C5: 합성곱 층 (출력: 120x1x1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0)\n",
    "        # F6: 완전 연결층 (출력: 84)\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        # Output: 완전 연결층 (출력: 10)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 크기: (batch_size, 1, 28, 28)\n",
    "        # LeNet-5는 32x32 입력을 기대하지만, MNIST는 28x28이므로 패딩을 추가\n",
    "        x = F.pad(x, (2, 2, 2, 2))  # 패딩 추가하여 32x32로 변환\n",
    "        x = F.relu(self.conv1(x))    # C1\n",
    "        x = self.pool1(x)            # S2\n",
    "        x = F.relu(self.conv2(x))    # C3\n",
    "        x = self.pool2(x)            # S4\n",
    "        x = F.relu(self.conv3(x))    # C5 120x1x1 \n",
    "        x = x.view(x.size(0), -1)    # Flatten 64x120의 2차원 텐서로 변경\n",
    "        x = F.relu(self.fc1(x))      # F6\n",
    "        x = self.fc2(x)              # Output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet5 Modeling\n",
    "#### 1 - 1st conv : 커널 사이즈 5x5\n",
    "- 입력 : 1채널의 32x32 이미지\n",
    "- 출력 : 6채널의 28x28 이미지\n",
    "- **stride=1**은 컨볼루션 연산 시 건너 뛰는 간격으로, 보통 모든 픽셀에 대해 컨볼루션 수행하므로 1로 설정함\n",
    "\n",
    "#### RELU 함수 적용1\n",
    "\n",
    "#### 2 - 1st pool : 커널 사이즈 2x2 \n",
    "- 입력 : 6채널의 28x28 이미지\n",
    "- 출력 : 6채널의 14x14 이미지\n",
    "\n",
    "#### 3 - 2nd conv : 커널 사이즈 5x5 \n",
    "- 입력 : 6채널의 14x14 이미지 \n",
    "- 출력 : 16채널의 10x10 이미지 (padding 없이 5x5 커널을 사용했으므로 상하좌우로 2라인씩 줄어들어 10x10이 됨)\n",
    "-> 6x14x14에 **16개의 5x5 커널**과 컨볼루션 연산 하면 16x10x10이 됨\n",
    "\n",
    "#### RELU 함수 적용2\n",
    "\n",
    "#### 4 - 2nd pool : 커널 사이즈 2x2\n",
    "- 입력 : 16채널의 10x10 이미지\n",
    "- 출력 : 16채널의 5x5 이미지\n",
    "\n",
    "#### 5 - 3rd conv : 커널 사이즈 5x5\n",
    "- 입력 : 16채널의 5x5 이미지 \n",
    "- 출력 : 120채널의 1x1 이미지\n",
    "\n",
    "#### RELU 함수 적용3\n",
    "\n",
    "#### 6 - FCL1\n",
    "- 입력 : 120 차원 벡터 [[x1, x2, x3, ... ,x120]]\n",
    "- 출력 : 84 차원 벡터 [[x1, x2, x3, ... ,x84]]\n",
    "\n",
    "#### RELU 함수 적용4 \n",
    "\n",
    "#### 7 - FCL2\n",
    "- 입력 : 84 차원 벡터 [[x1, x2, x3, ... ,x84]]\n",
    "- 출력 : 10 차원 벡터 [[x1, x2, x3, ... ,x10]] **-> logit**\n",
    "\n",
    "---\n",
    "#### 멀티 채널에서의 컨볼루션 연산 \n",
    "입력: 32×32x3\n",
    "필터: 3x5×5, 총 6개.\n",
    "출력: 28x28x6\n",
    "하나의 필터는 입력 데이터의 모든 채널(3채널)에 대해 합성곱 연산을 수행한 후, 결과를 합산하여 하나의 피처맵 생성.\n",
    "6개의 필터가 독립적으로 작동하여 총 6개의 피처맵 생성. \n",
    "\n",
    "---\n",
    "#### Flatten\n",
    "- Fully Connected Layer를 통과하기 전에 Flatten 처리를 함\n",
    "- x.view(x.size(0), -1)\n",
    "- x는 120x1x1의 3차원 텐서이고, x.size(0)는 배치 사이즈를 의미 64\n",
    "- 64x120 크기의 2차원 텐서로 평탄화 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. 학습 함수\n",
    "# ========================\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device) \n",
    "    # 모델의 (정적 초기화 레이어의 파라미터 및 버퍼) cpu 디바이스로 보내짐 (근데 원래 cpu에서 생성되었음)\n",
    "    # 모델이 원래 cpu에서 생성되었으므로, 사실 위치를 변경하지 않으나, 코드의 일관성, 호환성, 안정성, 명확성을 위하여 코드로 명시하는 것이 좋음\n",
    "    # 추후 GPU에서 학습 시 모델을 GPU로 보내기 위해 값을 변경해주어야 함 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # 모델을 training mode로 전환\n",
    "        total_loss = 0 # loss 값 초기화 \n",
    "        for images, labels in train_loader: # 훈련 셋의 배치 단위로 images, lables 반환이 반복됨 \n",
    "            images, labels = images.to(device), labels.to(device) # 데이터x도 cpu 디바이스로 보냄. (마찬가지로 GPU로 변경 시 GPU로 보내짐)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images) # images만 모델에 입력\n",
    "            loss = criterion(outputs, labels) # 모델 출력 결과와 정답 비교하여 loss 계산 \n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad() # 옵티마이저의 기울기 초기화 \n",
    "            loss.backward() # 손실에 대한 기울기 계산 \n",
    "            optimizer.step() # 옵티마이저의 최적화 단계 수행\n",
    "\n",
    "            total_loss += loss.item() # 손실 누적 값 계산 \n",
    "        \n",
    "        # 한 Epoch에서의 평균 손실 출력\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. 평가 함수\n",
    "# ========================\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images) # output = 64 x 10 (배치 사이즈 x 10차원 행벡터)\n",
    "            _, predicted = torch.max(outputs, 1) # torch.max의 반환 값은 튜플 : 각 행의 최대값, 각 행의 최대값 인덱스\n",
    "            total += labels.size(0) # 현재 샘플 갯수 (배치 단위로 더함 64+64+ ... )\n",
    "            correct += (predicted == labels).sum().item() # (predicted == labels)는 Boolean 값이고, 이것 또한 batch size 단위로 계산됨. 즉 64 차원의 Boolean값이 저장된 텐서임\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5. 예측 시각화\n",
    "# ========================\n",
    "def visualize_predictions(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(test_loader) # test_loader를 iterator로 변환 (데이터를 직접 순회하기 위해)\n",
    "    images, labels = next(data_iter) # 이터레이터를 생성하고 바로 next()를 호출하면 맨 처음 값부터 가져 옴\n",
    "    images, labels = images[:5].to(device), labels[:5].to(device) # 처음부터 5까지 이미지랑 레이블을 디바이스로 보냄\n",
    "\n",
    "    # 모델 예측\n",
    "    outputs = model(images) # 모델에 이미지를 입력하고 아웃풋을 저장\n",
    "    _, preds = torch.max(outputs, 1) # 예측값을 preds 변수에 저장 \n",
    "\n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3)) # \n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[idx].item()}\\nPred: {preds[idx].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6. 메인 실행\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 하이퍼파라미터\n",
    "    batch_size = 64\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # 데이터 로드\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    # 모델 초기화\n",
    "    #model = CNN()\n",
    "    model = LeNet5()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 모델 학습\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # 모델 평가\n",
    "    evaluate_model(model, test_loader)\n",
    "\n",
    "    # 예측 시각화\n",
    "    visualize_predictions(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
