{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from tqdm.notebook import tqdm  # tqdm.auto 대신 tqdm.notebook 사용\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. 시드 고정 (재현성 확보)\n",
    "# ========================\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. 데이터 증강 클래스 정의 (가우시안 노이즈 추가)\n",
    "# ========================\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & preprocessing\n",
    "\n",
    "#### Data augmentation (데이터 증강) 처리 추가\n",
    "- Rotation, Affine Transformation을 통해 데이터 증강하여 *overfitting* 방지, *robustness* 증대, *Generalization* 성능을 기대할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. 데이터 로드 및 전처리 (교차 검증 포함)\n",
    "# ========================\n",
    "def load_data(batch_size=64):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomResizedCrop(\n",
    "            size=28,\n",
    "            scale=(0.8, 1.2),\n",
    "            ratio=(0.9, 1.1)\n",
    "        ),  # 랜덤 스케일링\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.1, 0.1)\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        AddGaussianNoise(\n",
    "            mean=0.,\n",
    "            std=0.1\n",
    "        ),  # 가우시안 노이즈 추가 \n",
    "        transforms.Normalize(\n",
    "            mean=(0.5,),\n",
    "            std=(0.5,)\n",
    "        )\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.5,),\n",
    "            std=(0.5,)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # 전체 학습 데이터셋 로드\n",
    "    full_train_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        transform=transform_train,\n",
    "        download=True\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=transform_test,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    return full_train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet5 Modeling\n",
    "**1 - 1st conv : 커널 사이즈 5x5**\n",
    "- 입력 : 1채널의 32x32 이미지\n",
    "- 출력 : 6채널의 28x28 이미지\n",
    "- *stride=1*은 컨볼루션 연산 시 건너 뛰는 간격으로, 보통 모든 픽셀에 대해 컨볼루션 수행하므로 1로 설정함\n",
    "\n",
    "**RELU 함수 적용1**\n",
    "\n",
    "**2 - 1st pool : 커널 사이즈 2x2**\n",
    "- 입력 : 6채널의 28x28 이미지\n",
    "- 출력 : 6채널의 14x14 이미지\n",
    "\n",
    "**3 - 2nd conv : 커널 사이즈 5x5**\n",
    "- 입력 : 6채널의 14x14 이미지 \n",
    "- 출력 : 16채널의 10x10 이미지 (padding 없이 5x5 커널을 사용했으므로 상하좌우로 2라인씩 줄어들어 10x10이 됨)\n",
    "-> 6x14x14에 *16개의 5x5 커널*과 컨볼루션 연산 하면 16x10x10이 됨\n",
    "\n",
    "**RELU 함수 적용2**\n",
    "\n",
    "**4 - 2nd pool : 커널 사이즈 2x2**\n",
    "- 입력 : 16채널의 10x10 이미지\n",
    "- 출력 : 16채널의 5x5 이미지\n",
    "\n",
    "**5 - 3rd conv : 커널 사이즈 5x5**\n",
    "- 입력 : 16채널의 5x5 이미지 \n",
    "- 출력 : 120채널의 1x1 이미지\n",
    "\n",
    "**RELU 함수 적용3**\n",
    "\n",
    "**conv 결과에 Flatten 처리**\n",
    "\n",
    "**6 - FCL1**\n",
    "- 입력 : 120 차원 벡터 [[x1, x2, x3, ... ,x120]]\n",
    "- 출력 : 84 차원 벡터 [[x1, x2, x3, ... ,x84]]\n",
    "\n",
    "**RELU 함수 적용4**\n",
    "\n",
    "**7 - FCL2**\n",
    "- 입력 : 84 차원 벡터 [[x1, x2, x3, ... ,x84]]\n",
    "- 출력 : 10 차원 벡터 [[x1, x2, x3, ... ,x10]] **-> logit**\n",
    "\n",
    "---\n",
    "#### 멀티 채널에서의 컨볼루션 연산 \n",
    "입력: 32×32x3\n",
    "필터: 3x5×5, 총 6개.\n",
    "출력: 28x28x6\n",
    "하나의 필터는 입력 데이터의 모든 채널(3채널)에 대해 합성곱 연산을 수행한 후, 결과를 합산하여 하나의 피처맵 생성.\n",
    "6개의 필터가 독립적으로 작동하여 총 6개의 피처맵 생성. \n",
    "\n",
    "---\n",
    "#### Flatten 처리\n",
    "- Fully Connected Layer를 통과하기 전에 Flatten 처리를 함\n",
    "- x.view(x.size(0), -1)\n",
    "- x는 120x1x1의 3차원 텐서이고, x.size(0)는 배치 사이즈를 의미 64\n",
    "- 64x120 크기의 2차원 텐서로 평탄화 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. 모델 정의 (LeNet5)\n",
    "# ========================\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            num_features=6\n",
    "        )\n",
    "        self.pool1 = nn.AvgPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            num_features=16\n",
    "        )\n",
    "        self.pool2 = nn.AvgPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=120,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=120,\n",
    "            out_features=84\n",
    "        )\n",
    "        self.dropout = nn.Dropout(\n",
    "            p=dropout_rate\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=84,\n",
    "            out_features=10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (2, 2, 2, 2))  # 입력 이미지를 32x32로 패딩\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # 플래튼\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ========================\n",
    "# 5. 학습 함수 정의\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5, early_stopping_patience=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device) \n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # 스케줄러 업데이트 (ReduceLROnPlateau의 경우)\n",
    "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # 조기 종료 조건 확인\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6. 평가 함수 정의\n",
    "# ========================\n",
    "def evaluate_model_accuracy(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7. 교차 검증 함수 정의\n",
    "# ========================\n",
    "def cross_validate(model_class, dataset, k=5, params=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold + 1}\")\n",
    "        # 데이터 로더 생성\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=params['batch_size'],\n",
    "            sampler=train_subsampler\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=params['batch_size'],\n",
    "            sampler=val_subsampler\n",
    "        )\n",
    "        \n",
    "        # 모델 초기화\n",
    "        model = model_class(dropout_rate=params['dropout_rate']).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "        \n",
    "        # 학습률 스케줄러 초기화 (ReduceLROnPlateau)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            patience=params['scheduler_patience'],\n",
    "            factor=params['scheduler_factor'],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # 모델 학습\n",
    "        train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            num_epochs=params['num_epochs'],\n",
    "            early_stopping_patience=params['early_stopping_patience']\n",
    "        )\n",
    "        \n",
    "        # 모델 평가\n",
    "        accuracy = evaluate_model_accuracy(model, val_loader)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.2f}%\\n\")\n",
    "    \n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(f\"Average Accuracy over {k} folds: {average_accuracy:.2f}%\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:27:06,523] A new study created in memory with name: no-name-b7cdc490-27db-4553-8d13-a59df7b0f708\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10984\\1165575615.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10984\\1165575615.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 2.2338\n",
      "Epoch [2/7], Loss: 1.6289\n",
      "Epoch [3/7], Loss: 1.2569\n",
      "Epoch [4/7], Loss: 1.1172\n",
      "Epoch [5/7], Loss: 1.0190\n",
      "Epoch [6/7], Loss: 0.9239\n",
      "Epoch [7/7], Loss: 0.8319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:30:06,381] Trial 0 finished with value: 88.52 and parameters: {'learning_rate': 4.3523031064467625e-05, 'batch_size': 256, 'dropout_rate': 0.39460903934704766, 'num_epochs': 7}. Best is trial 0 with value: 88.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4594\n",
      "Epoch [2/10], Loss: 0.7553\n",
      "Epoch [3/10], Loss: 0.4828\n",
      "Epoch [4/10], Loss: 0.3433\n",
      "Epoch [5/10], Loss: 0.2737\n",
      "Epoch [6/10], Loss: 0.2304\n",
      "Epoch [7/10], Loss: 0.2078\n",
      "Epoch [8/10], Loss: 0.1851\n",
      "Epoch [9/10], Loss: 0.1749\n",
      "Epoch [10/10], Loss: 0.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:34:40,020] Trial 1 finished with value: 97.62 and parameters: {'learning_rate': 0.0001517854182516807, 'batch_size': 128, 'dropout_rate': 0.2291306022294895, 'num_epochs': 10}. Best is trial 1 with value: 97.62.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 2.3008\n",
      "Epoch [2/15], Loss: 2.2324\n",
      "Epoch [3/15], Loss: 1.9735\n",
      "Epoch [4/15], Loss: 1.6458\n",
      "Epoch [5/15], Loss: 1.4287\n",
      "Epoch [6/15], Loss: 1.2982\n",
      "Epoch [7/15], Loss: 1.2176\n",
      "Epoch [8/15], Loss: 1.1519\n",
      "Epoch [9/15], Loss: 1.1028\n",
      "Epoch [10/15], Loss: 1.0605\n",
      "Epoch [11/15], Loss: 1.0219\n",
      "Epoch [12/15], Loss: 0.9778\n",
      "Epoch [13/15], Loss: 0.9360\n",
      "Epoch [14/15], Loss: 0.8980\n",
      "Epoch [15/15], Loss: 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:41:44,248] Trial 2 finished with value: 88.72 and parameters: {'learning_rate': 1.2055237638131643e-05, 'batch_size': 128, 'dropout_rate': 0.44837154022584036, 'num_epochs': 15}. Best is trial 1 with value: 97.62.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Loss: 0.5013\n",
      "Epoch [2/8], Loss: 0.1413\n",
      "Epoch [3/8], Loss: 0.1058\n",
      "Epoch [4/8], Loss: 0.0910\n",
      "Epoch [5/8], Loss: 0.0784\n",
      "Epoch [6/8], Loss: 0.0705\n",
      "Epoch [7/8], Loss: 0.0632\n",
      "Epoch [8/8], Loss: 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:44:53,994] Trial 3 finished with value: 99.2 and parameters: {'learning_rate': 0.005179258795539069, 'batch_size': 256, 'dropout_rate': 0.2497288713272615, 'num_epochs': 8}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6506\n",
      "Epoch [2/10], Loss: 0.1726\n",
      "Epoch [3/10], Loss: 0.1278\n",
      "Epoch [4/10], Loss: 0.1051\n",
      "Epoch [5/10], Loss: 0.0880\n",
      "Epoch [6/10], Loss: 0.0833\n",
      "Epoch [7/10], Loss: 0.0734\n",
      "Epoch [8/10], Loss: 0.0704\n",
      "Epoch [9/10], Loss: 0.0617\n",
      "Epoch [10/10], Loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:49:08,770] Trial 4 finished with value: 98.91 and parameters: {'learning_rate': 0.002845216908360668, 'batch_size': 256, 'dropout_rate': 0.4912760211258839, 'num_epochs': 10}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Loss: 0.2875\n",
      "Epoch [2/12], Loss: 0.1301\n",
      "Epoch [3/12], Loss: 0.1083\n",
      "Epoch [4/12], Loss: 0.1006\n",
      "Epoch [5/12], Loss: 0.0999\n",
      "Epoch [6/12], Loss: 0.0998\n",
      "Epoch [7/12], Loss: 0.0934\n",
      "Epoch [8/12], Loss: 0.0948\n",
      "Epoch [9/12], Loss: 0.0974\n",
      "Epoch [10/12], Loss: 0.0891\n",
      "Epoch [11/12], Loss: 0.0914\n",
      "Epoch [12/12], Loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:54:34,616] Trial 5 finished with value: 98.58 and parameters: {'learning_rate': 0.009517355632102839, 'batch_size': 64, 'dropout_rate': 0.3080505307547531, 'num_epochs': 12}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Loss: 1.4916\n",
      "Epoch [2/12], Loss: 0.6907\n",
      "Epoch [3/12], Loss: 0.3520\n",
      "Epoch [4/12], Loss: 0.2597\n",
      "Epoch [5/12], Loss: 0.2129\n",
      "Epoch [6/12], Loss: 0.1896\n",
      "Epoch [7/12], Loss: 0.1693\n",
      "Epoch [8/12], Loss: 0.1557\n",
      "Epoch [9/12], Loss: 0.1469\n",
      "Epoch [10/12], Loss: 0.1368\n",
      "Epoch [11/12], Loss: 0.1300\n",
      "Epoch [12/12], Loss: 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 11:59:33,554] Trial 6 finished with value: 98.03 and parameters: {'learning_rate': 0.00030893735477430164, 'batch_size': 256, 'dropout_rate': 0.4543683086111921, 'num_epochs': 12}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 1.9925\n",
      "Epoch [2/7], Loss: 1.2261\n",
      "Epoch [3/7], Loss: 1.0557\n",
      "Epoch [4/7], Loss: 0.9303\n",
      "Epoch [5/7], Loss: 0.8030\n",
      "Epoch [6/7], Loss: 0.6752\n",
      "Epoch [7/7], Loss: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:02:17,196] Trial 7 finished with value: 92.15 and parameters: {'learning_rate': 9.283242308523981e-05, 'batch_size': 256, 'dropout_rate': 0.30120597524102366, 'num_epochs': 7}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/16], Loss: 1.9973\n",
      "Epoch [2/16], Loss: 1.2823\n",
      "Epoch [3/16], Loss: 1.1315\n",
      "Epoch [4/16], Loss: 1.0426\n",
      "Epoch [5/16], Loss: 0.9436\n",
      "Epoch [6/16], Loss: 0.8450\n",
      "Epoch [7/16], Loss: 0.7268\n",
      "Epoch [8/16], Loss: 0.6155\n",
      "Epoch [9/16], Loss: 0.5238\n",
      "Epoch [10/16], Loss: 0.4570\n",
      "Epoch [11/16], Loss: 0.4091\n",
      "Epoch [12/16], Loss: 0.3700\n",
      "Epoch [13/16], Loss: 0.3421\n",
      "Epoch [14/16], Loss: 0.3177\n",
      "Epoch [15/16], Loss: 0.3032\n",
      "Epoch [16/16], Loss: 0.2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:08:55,117] Trial 8 finished with value: 96.02 and parameters: {'learning_rate': 2.8109683593152463e-05, 'batch_size': 64, 'dropout_rate': 0.36001066716409547, 'num_epochs': 16}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/18], Loss: 2.1974\n",
      "Epoch [2/18], Loss: 1.4751\n",
      "Epoch [3/18], Loss: 1.1622\n",
      "Epoch [4/18], Loss: 1.0062\n",
      "Epoch [5/18], Loss: 0.8670\n",
      "Epoch [6/18], Loss: 0.7315\n",
      "Epoch [7/18], Loss: 0.6022\n",
      "Epoch [8/18], Loss: 0.5093\n",
      "Epoch [9/18], Loss: 0.4427\n",
      "Epoch [10/18], Loss: 0.3949\n",
      "Epoch [11/18], Loss: 0.3558\n",
      "Epoch [12/18], Loss: 0.3268\n",
      "Epoch [13/18], Loss: 0.3051\n",
      "Epoch [14/18], Loss: 0.2782\n",
      "Epoch [15/18], Loss: 0.2652\n",
      "Epoch [16/18], Loss: 0.2506\n",
      "Epoch [17/18], Loss: 0.2360\n",
      "Epoch [18/18], Loss: 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:15:51,392] Trial 9 finished with value: 96.92 and parameters: {'learning_rate': 6.287835780694528e-05, 'batch_size': 256, 'dropout_rate': 0.4963563954992604, 'num_epochs': 18}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6458\n",
      "Epoch [2/5], Loss: 0.1912\n",
      "Epoch [3/5], Loss: 0.1420\n",
      "Epoch [4/5], Loss: 0.1158\n",
      "Epoch [5/5], Loss: 0.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:17:52,629] Trial 10 finished with value: 98.0 and parameters: {'learning_rate': 0.0012608663449258305, 'batch_size': 128, 'dropout_rate': 0.2046192583855648, 'num_epochs': 5}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/9], Loss: 0.5181\n",
      "Epoch [2/9], Loss: 0.1431\n",
      "Epoch [3/9], Loss: 0.1116\n",
      "Epoch [4/9], Loss: 0.0894\n",
      "Epoch [5/9], Loss: 0.0767\n",
      "Epoch [6/9], Loss: 0.0694\n",
      "Epoch [7/9], Loss: 0.0629\n",
      "Epoch [8/9], Loss: 0.0588\n",
      "Epoch [9/9], Loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:21:13,166] Trial 11 finished with value: 99.01 and parameters: {'learning_rate': 0.004164080628099385, 'batch_size': 256, 'dropout_rate': 0.27175821782286164, 'num_epochs': 9}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/9], Loss: 0.7497\n",
      "Epoch [2/9], Loss: 0.2180\n",
      "Epoch [3/9], Loss: 0.1483\n",
      "Epoch [4/9], Loss: 0.1223\n",
      "Epoch [5/9], Loss: 0.1038\n",
      "Epoch [6/9], Loss: 0.0899\n",
      "Epoch [7/9], Loss: 0.0844\n",
      "Epoch [8/9], Loss: 0.0739\n",
      "Epoch [9/9], Loss: 0.0701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:25:03,668] Trial 12 finished with value: 98.96 and parameters: {'learning_rate': 0.0014614501168060989, 'batch_size': 256, 'dropout_rate': 0.26325610745195255, 'num_epochs': 9}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 0.3817\n",
      "Epoch [2/7], Loss: 0.1123\n",
      "Epoch [3/7], Loss: 0.0887\n",
      "Epoch [4/7], Loss: 0.0806\n",
      "Epoch [5/7], Loss: 0.0688\n",
      "Epoch [6/7], Loss: 0.0640\n",
      "Epoch [7/7], Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:27:46,863] Trial 13 finished with value: 98.7 and parameters: {'learning_rate': 0.00961442978065145, 'batch_size': 256, 'dropout_rate': 0.271857577796197, 'num_epochs': 7}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/14], Loss: 0.6357\n",
      "Epoch [2/14], Loss: 0.1858\n",
      "Epoch [3/14], Loss: 0.1372\n",
      "Epoch [4/14], Loss: 0.1131\n",
      "Epoch [5/14], Loss: 0.0956\n",
      "Epoch [6/14], Loss: 0.0800\n",
      "Epoch [7/14], Loss: 0.0755\n",
      "Epoch [8/14], Loss: 0.0705\n",
      "Epoch [9/14], Loss: 0.0650\n",
      "Epoch [10/14], Loss: 0.0626\n",
      "Epoch [11/14], Loss: 0.0581\n",
      "Epoch [12/14], Loss: 0.0559\n",
      "Epoch [13/14], Loss: 0.0537\n",
      "Epoch [14/14], Loss: 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:33:11,959] Trial 14 finished with value: 99.12 and parameters: {'learning_rate': 0.0031422795753992647, 'batch_size': 256, 'dropout_rate': 0.2479430958664263, 'num_epochs': 14}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/14], Loss: 0.6874\n",
      "Epoch [2/14], Loss: 0.2001\n",
      "Epoch [3/14], Loss: 0.1459\n",
      "Epoch [4/14], Loss: 0.1239\n",
      "Epoch [5/14], Loss: 0.1052\n",
      "Epoch [6/14], Loss: 0.0917\n",
      "Epoch [7/14], Loss: 0.0857\n",
      "Epoch [8/14], Loss: 0.0783\n",
      "Epoch [9/14], Loss: 0.0742\n",
      "Epoch [10/14], Loss: 0.0676\n",
      "Epoch [11/14], Loss: 0.0629\n",
      "Epoch [12/14], Loss: 0.0592\n",
      "Epoch [13/14], Loss: 0.0570\n",
      "Epoch [14/14], Loss: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:38:54,694] Trial 15 finished with value: 99.02 and parameters: {'learning_rate': 0.0006528379527849571, 'batch_size': 64, 'dropout_rate': 0.3381753702896116, 'num_epochs': 14}. Best is trial 3 with value: 99.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/18], Loss: 0.6208\n",
      "Epoch [2/18], Loss: 0.1710\n",
      "Epoch [3/18], Loss: 0.1193\n",
      "Epoch [4/18], Loss: 0.0973\n",
      "Epoch [5/18], Loss: 0.0845\n",
      "Epoch [6/18], Loss: 0.0761\n",
      "Epoch [7/18], Loss: 0.0665\n",
      "Epoch [8/18], Loss: 0.0621\n",
      "Epoch [9/18], Loss: 0.0597\n",
      "Epoch [10/18], Loss: 0.0541\n",
      "Epoch [11/18], Loss: 0.0529\n",
      "Epoch [12/18], Loss: 0.0480\n",
      "Epoch [13/18], Loss: 0.0456\n",
      "Epoch [14/18], Loss: 0.0460\n",
      "Epoch [15/18], Loss: 0.0458\n",
      "Epoch [16/18], Loss: 0.0427\n",
      "Epoch [17/18], Loss: 0.0397\n",
      "Epoch [18/18], Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:45:34,743] Trial 16 finished with value: 99.28 and parameters: {'learning_rate': 0.0029079897364446237, 'batch_size': 256, 'dropout_rate': 0.2354694644424466, 'num_epochs': 18}. Best is trial 16 with value: 99.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3519\n",
      "Epoch [2/20], Loss: 0.5268\n",
      "Epoch [3/20], Loss: 0.3324\n",
      "Epoch [4/20], Loss: 0.2572\n",
      "Epoch [5/20], Loss: 0.2096\n",
      "Epoch [6/20], Loss: 0.1808\n",
      "Epoch [7/20], Loss: 0.1649\n",
      "Epoch [8/20], Loss: 0.1543\n",
      "Epoch [9/20], Loss: 0.1397\n",
      "Epoch [10/20], Loss: 0.1297\n",
      "Epoch [11/20], Loss: 0.1238\n",
      "Epoch [12/20], Loss: 0.1162\n",
      "Epoch [13/20], Loss: 0.1061\n",
      "Epoch [14/20], Loss: 0.1022\n",
      "Epoch [15/20], Loss: 0.1042\n",
      "Epoch [16/20], Loss: 0.0956\n",
      "Epoch [17/20], Loss: 0.0927\n",
      "Epoch [18/20], Loss: 0.0908\n",
      "Epoch [19/20], Loss: 0.0875\n",
      "Epoch [20/20], Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 12:53:11,521] Trial 17 finished with value: 98.44 and parameters: {'learning_rate': 0.00040361844541395123, 'batch_size': 256, 'dropout_rate': 0.2036298054860092, 'num_epochs': 20}. Best is trial 16 with value: 99.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.4278\n",
      "Epoch [2/20], Loss: 0.1411\n",
      "Epoch [3/20], Loss: 0.1046\n",
      "Epoch [4/20], Loss: 0.0877\n",
      "Epoch [5/20], Loss: 0.0751\n",
      "Epoch [6/20], Loss: 0.0658\n",
      "Epoch [7/20], Loss: 0.0622\n",
      "Epoch [8/20], Loss: 0.0567\n",
      "Epoch [9/20], Loss: 0.0542\n",
      "Epoch [10/20], Loss: 0.0496\n",
      "Epoch [11/20], Loss: 0.0478\n",
      "Epoch [12/20], Loss: 0.0482\n",
      "Epoch [13/20], Loss: 0.0451\n",
      "Epoch [14/20], Loss: 0.0429\n",
      "Epoch [15/20], Loss: 0.0402\n",
      "Epoch [16/20], Loss: 0.0421\n",
      "Epoch [17/20], Loss: 0.0376\n",
      "Epoch [18/20], Loss: 0.0380\n",
      "Epoch [19/20], Loss: 0.0363\n",
      "Epoch [20/20], Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 13:02:07,703] Trial 18 finished with value: 99.14 and parameters: {'learning_rate': 0.0013085347594247534, 'batch_size': 64, 'dropout_rate': 0.3191341577172339, 'num_epochs': 20}. Best is trial 16 with value: 99.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/17], Loss: 0.4191\n",
      "Epoch [2/17], Loss: 0.1230\n",
      "Epoch [3/17], Loss: 0.0943\n",
      "Epoch [4/17], Loss: 0.0819\n",
      "Epoch [5/17], Loss: 0.0745\n",
      "Epoch [6/17], Loss: 0.0689\n",
      "Epoch [7/17], Loss: 0.0647\n",
      "Epoch [8/17], Loss: 0.0623\n",
      "Epoch [9/17], Loss: 0.0670\n",
      "Epoch [10/17], Loss: 0.0602\n",
      "Epoch [11/17], Loss: 0.0585\n",
      "Epoch [12/17], Loss: 0.0562\n",
      "Epoch [13/17], Loss: 0.0567\n",
      "Epoch [14/17], Loss: 0.0526\n",
      "Epoch [15/17], Loss: 0.0508\n",
      "Epoch [16/17], Loss: 0.0514\n",
      "Epoch [17/17], Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 13:09:14,655] Trial 19 finished with value: 98.96 and parameters: {'learning_rate': 0.005000055388406933, 'batch_size': 128, 'dropout_rate': 0.3727698859983155, 'num_epochs': 17}. Best is trial 16 with value: 99.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Accuracy: 99.28%\n",
      "  Params: \n",
      "    learning_rate: 0.0029079897364446237\n",
      "    batch_size: 256\n",
      "    dropout_rate: 0.2354694644424466\n",
      "    num_epochs: 18\n",
      "Epoch [1/18], Loss: 0.6476\n",
      "Epoch [2/18], Loss: 0.1703\n",
      "Epoch [3/18], Loss: 0.1145\n",
      "Epoch [4/18], Loss: 0.0926\n",
      "Epoch [5/18], Loss: 0.0798\n",
      "Epoch [6/18], Loss: 0.0709\n",
      "Epoch [7/18], Loss: 0.0661\n",
      "Epoch [8/18], Loss: 0.0586\n",
      "Epoch [9/18], Loss: 0.0521\n",
      "Epoch [10/18], Loss: 0.0517\n",
      "Epoch [11/18], Loss: 0.0508\n",
      "Epoch [12/18], Loss: 0.0476\n",
      "Epoch [13/18], Loss: 0.0486\n",
      "Epoch [14/18], Loss: 0.0467\n",
      "Epoch [15/18], Loss: 0.0433\n",
      "Epoch [16/18], Loss: 0.0437\n",
      "Epoch [17/18], Loss: 0.0432\n",
      "Epoch [18/18], Loss: 0.0395\n",
      "Final Accuracy with Best Params: 99.13%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# 8. Optuna를 사용한 하이퍼파라미터 튜닝 (교차 검증 포함)\n",
    "# ========================\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # 하이퍼파라미터 제안\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 5, 20)\n",
    "        early_stopping_patience = trial.suggest_int('early_stopping_patience', 3, 10)\n",
    "        \n",
    "        # ReduceLROnPlateau의 하이퍼파라미터 제안\n",
    "        scheduler_patience = trial.suggest_int('scheduler_patience', 2, 5)\n",
    "        scheduler_factor = trial.suggest_float('scheduler_factor', 0.1, 0.5, step=0.1)\n",
    "        \n",
    "        # 데이터 로드\n",
    "        full_train_dataset, _ = load_data(batch_size)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        params = {\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'num_epochs': num_epochs,\n",
    "            'early_stopping_patience': early_stopping_patience,\n",
    "            'scheduler_patience': scheduler_patience,\n",
    "            'scheduler_factor': scheduler_factor\n",
    "        }\n",
    "        \n",
    "        average_accuracy = cross_validate(LeNet5, full_train_dataset, k=5, params=params)\n",
    "        \n",
    "        return average_accuracy\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during trial: {e}\")\n",
    "        return 0  # 에러 발생 시 최소 정확도로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 9. Optuna 스터디 생성 및 최적화 실행\n",
    "# ========================\n",
    "def run_optuna_study(n_trials=20):\n",
    "    # Optuna 스터디 생성 (목표는 최대화, 즉 정확도 최대화)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # 최적화 실행\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    if study.best_trial is not None:\n",
    "        print(\"Best trial:\")\n",
    "        trial = study.best_trial\n",
    "\n",
    "        print(f\"  Accuracy: {trial.value:.2f}%\")\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "        \n",
    "        # 하이퍼파라미터 저장\n",
    "        with open('outputs/best_hyperparameters.json', 'w') as f:\n",
    "            json.dump(trial.params, f, indent=4)\n",
    "        print(\"하이퍼파라미터가 'outputs/best_hyperparameters.json' 파일로 저장되었습니다.\")\n",
    "        \n",
    "        return trial.params, study\n",
    "    else:\n",
    "        print(\"No successful trials found.\")\n",
    "        return None, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 10. 모델 저장 및 불러오기\n",
    "# ========================\n",
    "def save_model(model, path='outputs/best_lenet5_mnist.pth'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"모델이 '{path}' 파일로 저장되었습니다.\")\n",
    "\n",
    "def load_model(path='outputs/best_lenet5_mnist.pth', dropout_rate=0.5):\n",
    "    model = LeNet5(dropout_rate=dropout_rate)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"모델이 '{path}' 파일에서 불러와졌습니다.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 11. 예측 시각화\n",
    "# ========================\n",
    "def visualize_predictions(model, test_loader, num_images=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images[:num_images].to(device), labels[:num_images].to(device)\n",
    "\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 6))\n",
    "\n",
    "    for idx in range(num_images):\n",
    "        # 원본 이미지\n",
    "        ax = axes[0, idx]\n",
    "        img = images[idx].cpu().squeeze()\n",
    "        img = img * 0.5 + 0.5  # 정규화 해제\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[idx].item()}')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # 예측된 이미지\n",
    "        ax = axes[1, idx]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f'Pred: {preds[idx].item()}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 12. 메인 함수 정의\n",
    "# ========================\n",
    "def main():\n",
    "    # Optuna 하이퍼파라미터 튜닝 실행\n",
    "    best_params, study = run_optuna_study(n_trials=20)\n",
    "    \n",
    "    if best_params is not None:\n",
    "        # 데이터 로드\n",
    "        full_train_dataset, test_dataset = load_data(best_params['batch_size'])\n",
    "        \n",
    "        # 전체 학습 데이터 로드\n",
    "        # Optuna에서 사용한 전체 학습 데이터를 다시 사용하지 않고, 전체 데이터로 다시 학습\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            full_train_dataset,\n",
    "            batch_size=best_params['batch_size'],\n",
    "            shuffle=True\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=best_params['batch_size'],\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # 모델 초기화\n",
    "        best_model = LeNet5(dropout_rate=best_params['dropout_rate'])\n",
    "        \n",
    "        # 손실 함수 및 최적화 알고리즘\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "        \n",
    "        # 학습률 스케줄러 초기화 (ReduceLROnPlateau)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            patience=best_params['scheduler_patience'],\n",
    "            factor=best_params['scheduler_factor'],\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 모델 학습\n",
    "        train_model(\n",
    "            best_model,\n",
    "            train_loader,\n",
    "            test_loader,  # 여기서는 검증 데이터를 테스트 데이터로 사용\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            num_epochs=best_params['num_epochs'],\n",
    "            early_stopping_patience=best_params['early_stopping_patience']\n",
    "        )\n",
    "        \n",
    "        # 최종 평가\n",
    "        final_accuracy = evaluate_model_accuracy(best_model, test_loader)\n",
    "        print(f\"Final Accuracy with Best Params: {final_accuracy:.2f}%\")\n",
    "        \n",
    "        # 예측 시각화\n",
    "        visualize_predictions(best_model, test_loader, num_images=5)\n",
    "        \n",
    "        # 모델 저장\n",
    "        save_model(best_model, 'outputs/best_lenet5_mnist.pth')\n",
    "        \n",
    "        # Optuna 시각화\n",
    "        fig1 = plot_optimization_history(study)\n",
    "        fig1.savefig('outputs/optimization_history.png')\n",
    "        print(\"Optuna 최적화 히스토리가 'outputs/optimization_history.png'로 저장되었습니다.\")\n",
    "        \n",
    "        fig2 = plot_param_importances(study)\n",
    "        fig2.savefig('outputs/param_importances.png')\n",
    "        print(\"Optuna 파라미터 중요도가 'outputs/param_importances.png'로 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"최적의 하이퍼파라미터를 찾지 못했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 디렉토리 생성\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
