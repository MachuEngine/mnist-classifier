## ✍️ MNIST 숫자 분류 프로젝트: LeNet-5 모델 심층 분석

---

### 📚 프로젝트 개요
MNIST 데이터셋을 활용해 손글씨 숫자를 분류하는 딥러닝 모델을 구축하고, 그 과정에서 공부한 내용을 기록합니다.
단순히 모델을 만드는 것을 넘어, LeNet-5 아키텍처를 구현하고 다양한 최적화 기법을 적용하며 모델의 성능을 깊이 있게 공부하려고 햇습니다. 

**주요 목표: LeNet-5 모델을 구현하고, 데이터 증강 및 하이퍼파라미터 튜닝을 통해 MNIST 분류 정확도를 극대화** 
사용 기술: PyTorch, Optuna, scikit-learn
결과: 최종 테스트 정확도 99.28% 달성

- MNIST 데이터셋을 사용하여 손글씨 숫자(0~9)를 분류하는 합성곱 신경망(CNN) 모델 및 LeNet5 아키텍처를 구현
- 교차 검증 및 하이퍼파라미터 최적화를 통해 결과를 비교 분석

---

###💡 프로젝트를 통해 배운 점 및 느낀 점

**1. 하이퍼파라미터 튜닝의 중요성**

초기에 기본적인 LeNet-5 모델을 학습시켰을 때 약 99.00%의 정확도를 얻었습니다. 이미 높은 수치였지만, Optuna 라이브러리를 활용해 학습률, 배치 크기, 드롭아웃 비율 등을 최적화한 결과 **99.28%**라는 더 높은 정확도를 달성할 수 있었습니다. 이는 단순히 좋은 모델을 사용하는 것뿐만 아니라, 그 모델에 맞는 최적의 설정을 찾는 것이 얼마나 중요한지 깨닫게 해준 경험이었습니다. 특히, 학습률 스케줄러를 적용하여 검증 손실이 정체될 때 학습률을 낮추는 전략은 모델의 안정적인 수렴에 큰 도움이 되었습니다. 이 부분에서 이론적으로 배운 gradient descent 기법에서 가변적으로 학습률을 적용하는게 도움이 된다는것이 체감되었습니다. 

**2. 이론과 실제의 차이: 데이터 증강**

MNIST 데이터셋은 비교적 단순하고 깨끗하기 때문에, 데이터 증강이 큰 효과를 보지 못할 것이라고 생각했습니다. 하지만 랜덤 회전, 크기 조정 등의 기법을 적용한 결과, 모델의 일반화 성능이 미세하게나마 향상되는 것을 확인할 수 있었습니다. 이를 통해 아무리 간단한 데이터셋이라도 데이터의 다양성을 확보하려는 노력이 모델의 견고함을 높이는 데 기여한다는 것을 체감했습니다.

**3. 교차 검증의 필요성**

단일 학습/검증 세트로 모델을 평가할 때, 특정 데이터 분할에 따라 결과가 다르게 나올 수 있습니다. 이를 방지하기 위해 K-Fold 교차 검증을 적용했고, 모델의 성능을 보다 객관적이고 신뢰성 있게 평가할 수 있었습니다. 이는 단순히 높은 정확도 수치에 만족하는 것이 아니라, 모델의 성능을 다각도로 검증하는 습관의 중요성을 알려주었습니다.

**4. 코드의 가독성과 재사용성**

튜토리얼 형식의 프로젝트였지만, 함수와 클래스를 명확하게 나누고 매개변수를 명시적으로 지정하여 코드의 가독성을 높였습니다. 이는 향후 코드를 수정하거나 다른 프로젝트에 재사용할 때 시간을 크게 절약할 수 있다는 것을 보여주었습니다.

---

### 📈 모델 성능 분석
LeNet-5 + 최적화 기법 적용
- 최종 테스트 정확도: 99.28%

**하이퍼파라미터 튜닝 결과:**
- 학습률: 0.0029
- 배치 크기: 256
- 드롭아웃 비율: 0.235
- 에포크 수: 18
- 혼동 행렬 분석: 전반적으로 매우 높은 정확도를 보였으나, 3과 5, 4와 9 등 형태가 비슷한 숫자에서 일부 오분류가 발생했습니다. 이는 모델이 훈련 과정에서 착각할 수 있는 부분이며, 앞으로 더 깊은 모델이나 다른 모델을 적용하여 해결해 볼 수 있는 부분이라고 생각합니다.

---

### 🛠 기술 스택 및 레포 구조 정리
- 프레임워크: PyTorch
- 주요 라이브러리: torchvision, optuna, scikit-learn, matplotlib
- 저장소 구조:

```Bash
mnist-classification/
│
├── data/                 # 데이터셋
├── outputs/              # 학습 결과물 (그래프, 모델 체크포인트 등)
├── lenet5.py             # LeNet-5 모델 구현 및 학습 스크립트
├── requirements.txt      # 의존성 패키지 목록
└── README.md             # 현재 파일
```

---

### 🔗 참고 자료
이 프로젝트를 진행하는 데 참고했던 자료들입니다.
- [MNIST 데이터셋](http://yann.lecun.com/exdb/mnist/)
- [PyTorch 공식 문서](https://pytorch.org/docs/)
- [합성곱 신경망(CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network)
- [Optuna 공식 문서](https://optuna.readthedocs.io/en/stable/)
